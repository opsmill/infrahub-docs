---
title: Installing Infrahub Enterprise
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import VideoPlayer from '../../src/components/VideoPlayer';
import ReferenceLink from "../../src/components/Card";

# Installing Infrahub Enterprise

## Infrahub Enterprise

Enterprise is based off the Community version, with several changes for:

- enterprise features
- high availability
- better performance
- security hardening (Docker image, etc)

Infrahub Enterprise can be deployed the same way as Infrahub Community, using the curl method or using Helm:

- [Quick start via curl](#quick-start-via-curl)
- [K8s with Helm charts](#k8s-with-helm-charts)

## Hardware requirements

Please ensure the systems on which you want to install Infrahub Enterprise meet the [hardware requirements](../topics/hardware-requirements).

Allocating more CPU cores to the Neo4j database can improve performance since Infrahub Enterprise leverages parallel query execution.

## Quick start via curl

To quickly spin up the latest Infrahub locally, you can retrieve the Docker Compose file from [infrahub.opsmill.io/enterprise](https://infrahub.opsmill.io/enterprise).

### To spin up an Infrahub environment

<Tabs>
<TabItem value="MacOS" default>

```shell
curl https://infrahub.opsmill.io/enterprise | docker compose -p infrahub -f - up -d
```

</TabItem>
<TabItem value="Ubuntu">

```shell
curl https://infrahub.opsmill.io/enterprise | sudo docker compose -p infrahub -f - up -d
```

</TabItem>
</Tabs>

### To spin down and remove an Infrahub environment

<Tabs>
<TabItem value="MacOS" default>

```shell
curl https://infrahub.opsmill.io/enterprise | docker compose -p infrahub -f - down -v
```

</TabItem>
<TabItem value="Ubuntu">

```shell
curl https://infrahub.opsmill.io/enterprise | sudo docker compose -p infrahub -f - down -v
```

</TabItem>
</Tabs>

## K8s with Helm charts

Enterprise Helm chart is based of the original Infrahub chart and using it as a Helm dependency.
Thus most of the configuration related to Infrahub goes inside the `infrahub` top-level key.

<ReferenceLink title="Infrahub Helm Chart" url="https://github.com/opsmill/infrahub-helm/tree/stable/charts/infrahub-enterprise" openInNewTab />
<ReferenceLink title="ArtifactHub" url="https://artifacthub.io/packages/helm/infrahub-enterprise/infrahub-enterprise" openInNewTab />

The following are required for production deployments using Helm:

- data persistence for the database must be enabled
- multiple replicas of the Infrahub API Server and Infrahub Task workers should be deployed: you can make use of the `affinity` variable to define the affinity policy for the pods
- S3 storage should be configured for the Infrahub API Server, it is required if you have multiple replicas

:::warning

We do not recommend using the included dependencies (Neo4j, RabbitMQ, Redis) for production.
They are present to ease deployment on non-production environments.

:::

You can use the following values example:

```yaml
infrahub:
  infrahubServer:
    replicas: 3
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: service
                operator: In
                values:
                - infrahub-server
            topologyKey: topology.kubernetes.io/zone
    persistence:
      enabled: false
    ingress:
      enabled: true
    infrahubServer:
      env:
        INFRAHUB_ALLOW_ANONYMOUS_ACCESS: "true"
        INFRAHUB_CACHE_PORT: 6379
        INFRAHUB_CONFIG: /config/infrahub.toml
        INFRAHUB_DB_TYPE: neo4j
        INFRAHUB_LOG_LEVEL: INFO
        INFRAHUB_PRODUCTION: "true"
        INFRAHUB_INITIAL_ADMIN_TOKEN: 06438eb2-8019-4776-878c-0941b1f1d1ec
        INFRAHUB_SECURITY_SECRET_KEY: 327f747f-efac-42be-9e73-999f08f86b92
        INFRAHUB_STORAGE_DRIVER: s3
        AWS_ACCESS_KEY_ID: xxxx
        AWS_SECRET_ACCESS_KEY: xxxx
        AWS_S3_BUCKET_NAME: infrahub-data
        AWS_S3_ENDPOINT_URL: https://s3

  infrahubTaskWorker:
    replicas: 3
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: service
                operator: In
                values:
                - infrahub-task-worker
            topologyKey: topology.kubernetes.io/zone

  neo4j:
    services:
      admin:
        enabled: true
    volumes:
      data:
        mode: dynamic
        dynamic:
          storageClassName: premium-rwo
          requests:
            storage: 100Gi
```

```shell
helm install infrahub -f values.yml path/to/infrahub-enterprise/chart
```

You can also install the chart using the OpsMill registry.

```shell
helm install infrahub -f values.yml oci://registry.opsmill.io/opsmill/chart/infrahub-enterprise
```

## Backup and restore Infrahub Enterprise

Backing Infrahub Enterprise up consists of:

1. Backup the Neo4j database

  You can use the following tools to backup the Neo4j database: [Database Backup](./database-backup)
  Thanks to Neo4j Enterprise, you can leverage the online backup feature that does not require stopping the database.

2. Backup the artifact store

  Either the S3 bucket or the local filesystem, accordingly.

3. Backup the Prefect database (task logs, etc)

  You can use standard PostgreSQL tools like pg_dump
  For example, when running using Docker compose:

`docker exec infrahub-task-manager-db-1 pg_dump -Fc -d prefect -U postgres > prefect.dump`

Restoring Infrahub Enterprise consists of:

1. Starting Infrahub
2. Restoring the Neo4j database ([Database Restore](./database-backup#restore-a-backup-on-a-non-default-cypher-port))
3. Restoring the artifact store
4. Restoring the Prefect database

  For example, when running using Docker Compose:

  `docker exec infrahub-task-manager-db-1 pg_restore -d prefect -U postgres --clean --create prefect.dump`

  Then restart the task manager (Prefect server)

5. Restarting Infrahub (API servers, then task workers)

## High Availability

[High Availability Architecture](../topics/architecture#infrahub-high-availability-deployment)
